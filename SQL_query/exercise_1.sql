/*
-----------------------------------------------
Задача №1. Оптимизация.

У вас есть три таблицы:

Большая таблица №1:	
A (entry_id int, type_id int, amt number) 
Ключ: ENTRY_ID, TYPE_ID

Большая таблица №2:	
B (entry_id int, dt date, amt_new number) 
Ключ: ENTRY_ID

Справочник (маленькая таблица): 
XREF(type_id int, type varchar2(10))
Ключ: TYPE_ID
Одна строка таблицы А может относиться одновременно к нескольким типам, указанным в справочнике.

Необходимо вытащить из таблиц A и B значения AMT и AMT_NEW за даты: 
dt BETWEEN to_date('01.01.2014', 'dd.mm.yyyy') AND to_date('01.01.2016', 'dd.mm.yyyy') с типом TYPE = 'CURRENT'. Таблицы A и B имеют общий идентификатор - ENTRY_ID. 
Таблицы A и XREF имеют общий идентификатор типа - TYPE_ID.

Вопросы:
- Как наиболее оптимально выполнить соединение таблиц (нужно написать запрос, возвращающий ENTRY_ID, AMT, AMT_NEW)? 
- От чего это зависит и какой тип соединения вы ожидаете увидеть в плане запроса?
- Стали бы вы партицировать или индексировать таблицы? 
- Как и почему?
-----------------------------------------------

Ответы:

1) Как наиболее оптимально выполнить соединение таблиц (нужно написать запрос, возвращающий ENTRY_ID, AMT, AMT_NEW)? 
*/

	SELECT
	    A.ENTRY_ID,
	    A.AMT, 
	    B. AMT_NEW
	FROM A
	INNER JOIN B       ON A. entry_id =  B. entry_id
	INNER JOIN XREF ON XREF. type_id =  A. type_id
	WHERE XREF.type = 'CURRENT'
	AND   B.DT BETWEEN to_date('01.01.2014', 'dd.mm.yyyy') AND to_date('01.01.2016', 'dd.mm.yyyy')

/*
2) От чего это зависит и какой тип соединения вы ожидаете увидеть в плане запроса?
В общем виде тип соединения зависит от того, какой тип соединения планровщик запросов посчитает наиболее эффективным, опираясь на (схему БД, статистику БД, текст запроса, свободные ресурсы CPU/Memory). В нашем случае можно сфокусироваться на объёмах таблиц и ключевых полях.
В плане будет как минимум 2 соединения потоков данных. Скорее всего планировщик решит что эффективнее сначало провести фильтрацию, а потом Join. Предположим что большие таблицы даже после фильтрацииостануться большими.
Полагаю что соединение потока с таблицей  XREF будет происходить либо посредством Hash Match (если поток окажется достаточно велик) либо Nested Loops (если все участники соединения не велики в объеме и быстрее перебрать все строки, чем строить Hash таблицу).
Соединение же потоков таблиц A и B скорее всего произойдет с помощью Merge, поскольку поле entry_id в обеих таблицах находится в первичном ключе, а значит по ним построен кластеризованный индекс и таблицы отсортированы по entry_id, что является главным условием появления  Merge join в плане запроса.

3) Стали бы вы партицировать или индексировать таблицы? 
В первую очередь я смотрел бы на характер обращений к этим таблицам, если в них часто вставляются и/или обновляются строки, а чтение происходит редко, добавление индексов может привнести больше тормозов, чем пользы.

4) Как и почему?
Предположим что важно обеспечить максимально быстрое выполнение нашего запроса и таблицы A и B очень и очень большие. 
Соединеие всех таблиц происходит по полям из индесов, поэтому будет работать довольно эффективно. Можно сосредоточится на оптимизации секции WHERE:

- XREF.type = 'CURRENT'. Знаем, что XREF по условию не большая, и фильтрация идет по совпадению, то есть речь про поиск единственной строки в маленькой таблице. HASH индекс по полю XREF.type 	улучшил бы поиск по значению поля, но выигрыш будет не существенным, можно обойтись без индексов.
- B.DT BETWEEN to_date('01.01.2014', 'dd.mm.yyyy') AND to_date('01.01.2016', 'dd.mm.yyyy'). Знаем что таблица B большая и для фильтра по диапазону дат придется делать full scan, что не эффективно. Нам поможет добавление некластеризованного индекса B-tree по полю B.DT или же добавление  B.DT в первичный ключ (ENTRY_ID,DT) (если это не нарушит согласованность данных, логику схемы). B-tree, поскольку события по дням обычно распределенны +- равномерно (сбалансированно). Но если на каждую дату в таблице приходится очень много событий, может оказаться что индекс Bitmap по полю DT покажет лучшую эффективность при меньшем размере на диске. Истину можно установить экспериментально, или же посмотреть на статистику таблицы.

Если таблица B огромна, и данные за сильно прошлые периоды обновляются крайне редко, дополнительно можно разбить таблицу на парты/секции с ключом партиционирования to_year(DT) или to_month(DT), тогда можно будет при поиске сразу читать нужные парты. Ключ to_year(DT) будет проще поддерживать, я бы выбрал его, если это позволит объём данных.
*/